{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "533974aa-77d3-4d5a-b056-9a93cd6607cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from pathlib import Path\n",
    "from collections import namedtuple\n",
    "from datetime import datetime\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ecb31141-e3cc-48b9-9ee0-c5a505705c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking the average heart rate of each day for a patient\n",
    "# make an array that has patient id, average heart rate, day\n",
    "# given an input of the total patient heart rate csv file\n",
    "\n",
    "def timestamp_avg_hr(csv_file):\n",
    "    list_avg_hr = []\n",
    "    list_day_hr = []\n",
    "    \n",
    "    df = pd.read_csv(csv_file) # csv into dataframe\n",
    "\n",
    "    if df.empty or 'timestamp' not in df.columns or 'heartrate' not in df.columns:\n",
    "        return [],[]\n",
    "        \n",
    "    unix_prev = df['timestamp'].loc[0]\n",
    "    temp_day_prev = datetime.fromtimestamp(df['timestamp'].loc[0]).day # first day\n",
    "    temp_hr_sum = 0\n",
    "    counter = 0\n",
    "\n",
    "    for i in df.index: # iterates through each row\n",
    "        val = df['timestamp'].loc[i] # the timestamp value at that row\n",
    "        temp_day_curr = datetime.fromtimestamp(val).day # converting to # date\n",
    "        if temp_day_prev == temp_day_curr:\n",
    "            counter += 1\n",
    "            temp_hr_sum += df['heartrate'].loc[i]\n",
    "        elif temp_day_curr != temp_day_prev:\n",
    "            if (counter != 0):\n",
    "                list_day_hr.append(unix_prev) # add day to list\n",
    "                avg_hr = temp_hr_sum/counter\n",
    "                list_avg_hr.append(avg_hr)\n",
    "                temp_hr_sum = 0\n",
    "                counter = 0\n",
    "                unix_prev = df['timestamp'].loc[i]\n",
    "                temp_day_prev = temp_day_curr\n",
    "\n",
    "    # for last day otherwise not included\n",
    "    if (counter != 0):\n",
    "        unix_prev = df['timestamp'].loc[len(df.index)-1]\n",
    "        list_day_hr.append(unix_prev)\n",
    "        avg_hr = temp_hr_sum/counter\n",
    "        list_avg_hr.append(avg_hr)\n",
    "            \n",
    "    return list_avg_hr, list_day_hr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "03a7a2bf-9b19-4053-8b56-561ec06f09d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 1, 4, 5, 8, 9, 10, 11, 12, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 11, 12, 13, 14, 15, 16, 24, 25, 26, 27, 28, 1]\n"
     ]
    }
   ],
   "source": [
    "# testing\n",
    "hr,day = timestamp_avg_hr(r\"C:\\Users\\VictoriaAgain\\Downloads\\download\\02737ec6ea3d15c132c6d82ccc0fa7c0\\combined_heartrate.csv\")\n",
    "\n",
    "convert_day = []\n",
    "for i in range(len(day)):\n",
    "    convert_day.append(datetime.fromtimestamp(day[i]).day)\n",
    "# print(convert_day)\n",
    "print(convert_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a19b138a-a61e-4abb-a31d-f553b2e23274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total steps by day for one patient given csv file path\n",
    "\n",
    "def timestamp_total_step(csv_file):\n",
    "    list_total_step = []\n",
    "    list_day_step = []\n",
    "    \n",
    "    df = pd.read_csv(csv_file)\n",
    "\n",
    "    if df.empty or 'stop' not in df.columns or 'steps' not in df.columns:\n",
    "        return [],[]\n",
    "    \n",
    "    unix_prev = df['stop'].loc[0]\n",
    "    temp_day_prev = datetime.fromtimestamp(df['stop'].loc[0]).day\n",
    "    temp_total_step = 0\n",
    "    \n",
    "    for i in df.index:\n",
    "        val = df['stop'].loc[i]\n",
    "        temp_day_curr = datetime.fromtimestamp(val).day\n",
    "        if temp_day_prev == temp_day_curr:\n",
    "            temp_total_step += df['steps'].loc[i]\n",
    "        elif temp_day_curr != temp_day_prev:\n",
    "            list_day_step.append(unix_prev)\n",
    "            list_total_step.append(temp_total_step)\n",
    "            unix_prev = df['stop'].loc[i]\n",
    "            temp_total_step = 0\n",
    "            temp_day_prev = temp_day_curr\n",
    "\n",
    "    # for last day otherwise not included\n",
    "    unix_prev = df['stop'].loc[len(df.index)-1]\n",
    "    list_day_step.append(unix_prev)\n",
    "    list_total_step.append(temp_total_step)\n",
    "    \n",
    "    return list_total_step, list_day_step\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "8f581407-1343-49c1-a912-6d2d9d5dcd24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "# testing\n",
    "step,day = timestamp_total_step(r\"C:\\Users\\VictoriaAgain\\Downloads\\download\\02737ec6ea3d15c132c6d82ccc0fa7c0\\combined_steps.csv\")\n",
    "convert_day = []\n",
    "for i in range(len(day)):\n",
    "    convert_day.append(datetime.fromtimestamp(day[i]).day)\n",
    "print(convert_day)\n",
    "# df = pd.read_csv(r\"C:\\Users\\VictoriaAgain\\Downloads\\download\\90b8c2e2c843ffd77f8621c7d6ed044d\\combined_steps.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cbda3f10-eee4-4a84-9531-2954b471950d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining heart rate and step files for each patient\n",
    "# given the day is the same -- check month and day are the same, create new 2d array with same date and corresponding heart rate + steps\n",
    "# also return patient id via substring\n",
    "\n",
    "def compile_step_hr(hr_file,step_file):\n",
    "    step_arr, step_day = timestamp_total_step(step_file)\n",
    "    hr_arr, hr_day = timestamp_avg_hr(hr_file)\n",
    "    \n",
    "    list_day = []\n",
    "    list_hr = []\n",
    "    list_step = []\n",
    "\n",
    "    # smaller functions work -- same dates -- something here is WRONG\n",
    "    for i in range(np.minimum(len(hr_day),len(step_day))):  # whichever is smaller\n",
    "        hr_month = datetime.fromtimestamp(hr_day[i]).month\n",
    "        hr_datetime_day = datetime.fromtimestamp(hr_day[i]).day\n",
    "        step_month = datetime.fromtimestamp(step_day[i]).month\n",
    "        step_datetime_day = datetime.fromtimestamp(step_day[i]).day\n",
    "        \n",
    "        # need double for loop in case we skip a day!\n",
    "        # print(hr_month, \",\", hr_datetime_day)\n",
    "        # print(step_month, \",\", step_datetime_day)\n",
    "        if (hr_month == step_month and hr_datetime_day == step_datetime_day): # checking if date is the same\n",
    "            # print(hr_arr[i], step_arr[i])\n",
    "            list_day.append(hr_day[i])\n",
    "            list_hr.append(hr_arr[i])\n",
    "            list_step.append(step_arr[i])\n",
    "        elif (hr_datetime_day > step_datetime_day): # heartrate skips, go through rest of step days\n",
    "            for j in range(i,len(step_day)):\n",
    "                if (hr_month == step_month and hr_datetime_day == datetime.fromtimestamp(step_day[j]).day):\n",
    "                    list_day.append(hr_day[i])\n",
    "                    list_hr.append(hr_arr[i])\n",
    "                    list_step.append(step_arr[j])\n",
    "        elif (step_datetime_day > hr_datetime_day): # step day skips, go through rest of heart rate days\n",
    "            for k in range(i,len(hr_day)):\n",
    "                if (hr_month == step_month and step_datetime_day == datetime.fromtimestamp(hr_day[k]).day):\n",
    "                    list_day.append(hr_day[k])\n",
    "                    list_hr.append(hr_arr[k])\n",
    "                    list_step.append(step_arr[i])\n",
    "    \n",
    "    # testing\n",
    "    # list_day is correct, only shows same days in both lists\n",
    "    for i in range(len(list_day)):\n",
    "        convert_day.append(datetime.fromtimestamp(list_day[i]).day)\n",
    "    # print(len(list_day),len(list_hr),len(list_step))\n",
    "    list_patient_id = [str(hr_file)[42:74]]*len(list_day)\n",
    "    # print(len(list_patient_id))\n",
    "    # print(step_arr, datetime.fromtimestamp(step_day).day, hr_arr, datetime.fromtimestamp(hr_day).day)\n",
    "    combined_arr = np.column_stack((list_patient_id,list_day,list_hr,list_step))\n",
    "    # print(combined_arr)\n",
    "    return combined_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "f8434a47-2066-4ac8-9334-675eadd789fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['80929938f623f44614a029108a740d00', '1637412569.2489471',\n",
       "        '69.32836877807112', '4106.000000000001'],\n",
       "       ['80929938f623f44614a029108a740d00', '1637412569.2489471',\n",
       "        '69.32836877807112', '9930.58474614884'],\n",
       "       ['80929938f623f44614a029108a740d00', '1637412569.2489471',\n",
       "        '69.32836877807112', '5663.000000000003'],\n",
       "       ['80929938f623f44614a029108a740d00', '1637412569.2489471',\n",
       "        '69.32836877807112', '2448.044744116518'],\n",
       "       ['80929938f623f44614a029108a740d00', '1637412569.2489471',\n",
       "        '69.32836877807112', '4789.999999999996'],\n",
       "       ['80929938f623f44614a029108a740d00', '1637412569.2489471',\n",
       "        '69.32836877807112', '6616.503479757015'],\n",
       "       ['80929938f623f44614a029108a740d00', '1637470817.517382',\n",
       "        '65.38250787169845', '4864.040551797268'],\n",
       "       ['80929938f623f44614a029108a740d00', '1637470817.517382',\n",
       "        '65.38250787169845', '5695.129824384994'],\n",
       "       ['80929938f623f44614a029108a740d00', '1637470817.517382',\n",
       "        '65.38250787169845', '7751.000000000004'],\n",
       "       ['80929938f623f44614a029108a740d00', '1637470817.517382',\n",
       "        '65.38250787169845', '11183.307800243167'],\n",
       "       ['80929938f623f44614a029108a740d00', '1637470817.517382',\n",
       "        '65.38250787169845', '6752.000000000006'],\n",
       "       ['80929938f623f44614a029108a740d00', '1637470817.517382',\n",
       "        '65.38250787169845', '3735.190083442526'],\n",
       "       ['80929938f623f44614a029108a740d00', '1637592203.2239146',\n",
       "        '81.80271162654891', '7080.694108333209'],\n",
       "       ['80929938f623f44614a029108a740d00', '1637592203.2239146',\n",
       "        '81.80271162654891', '7509.584985772285'],\n",
       "       ['80929938f623f44614a029108a740d00', '1637592203.2239146',\n",
       "        '81.80271162654891', '5761.329828475496'],\n",
       "       ['80929938f623f44614a029108a740d00', '1637592203.2239146',\n",
       "        '81.80271162654891', '8407.434692921059'],\n",
       "       ['80929938f623f44614a029108a740d00', '1637592203.2239146',\n",
       "        '81.80271162654891', '4417.000000000004'],\n",
       "       ['80929938f623f44614a029108a740d00', '1637592203.2239146',\n",
       "        '81.80271162654891', '3760.5952748646214'],\n",
       "       ['80929938f623f44614a029108a740d00', '1637704280.3434532',\n",
       "        '77.89933235262647', '2259.000000000001'],\n",
       "       ['80929938f623f44614a029108a740d00', '1637704280.3434532',\n",
       "        '77.89933235262647', '2508.692864997305'],\n",
       "       ['80929938f623f44614a029108a740d00', '1637704280.3434532',\n",
       "        '77.89933235262647', '3062.9999999999995'],\n",
       "       ['80929938f623f44614a029108a740d00', '1637704280.3434532',\n",
       "        '77.89933235262647', '7955.372474038402'],\n",
       "       ['80929938f623f44614a029108a740d00', '1637704280.3434532',\n",
       "        '77.89933235262647', '5370.457878461109'],\n",
       "       ['80929938f623f44614a029108a740d00', '1637704280.3434532',\n",
       "        '77.89933235262647', '7791.98810964239']], dtype='<U32')"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing\n",
    "\n",
    "# taking array and turning into csv file\n",
    "arr = compile_step_hr(r\"C:\\Users\\VictoriaAgain\\Downloads\\download\\80929938f623f44614a029108a740d00\\combined_heartrate.csv\",r\"C:\\Users\\VictoriaAgain\\Downloads\\download\\80929938f623f44614a029108a740d00\\combined_steps.csv\")\n",
    "arr\n",
    "# df = pd.DataFrame(arr)\n",
    "# df.to_csv('temp_output.csv',index=False,header=False)\n",
    "# patient_id time hr step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "e6203f1b-d6a3-414a-876c-ac44ce3ac2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# given a folder go through each of the folders and create an array based on the combined heartrate and steps\n",
    "\n",
    "p = Path(\"C:/Users/VictoriaAgain/Downloads/download\")\n",
    "raw_files = list(p.rglob('*.csv*'))\n",
    "files = []\n",
    "all_files = []\n",
    "\n",
    "for i in range(len(raw_files)):\n",
    "    files.append(str(raw_files[i]).replace('\\\\','/'))\n",
    "for j in range(len(files)-1):\n",
    "    all_files.append(compile_step_hr(files[j],files[j+1]))\n",
    "\n",
    "final_df = pd.DataFrame(np.vstack(all_files),columns=['patient_id','timestamp','average_hr','steps'])\n",
    "final_df.to_csv('combined_files_avg_hr.csv',index=False,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d74efe50-36d0-48ff-873c-87e0583ec11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at different classification models!!\n",
    "# sk learn package -- regression tracking, classification -- try and use classifier!\n",
    "\n",
    "# new function -- go through all of the folders and json files, create a csv file with all of the daily PROMIS responses, days, and patient_id\n",
    "# if json file has daily faigue 1 item, put patient_id, promis score, and date in big csv file\n",
    "# go through both hr_step and promis_file, combined based on dates and patient_id\n",
    "\n",
    "def compile_fatigue(folder_path):\n",
    "    p = Path(folder_path)\n",
    "    raw_promis_files = list(p.rglob('*.json*')) # all json files\n",
    "    daily_promis_files = []\n",
    "    \n",
    "    for i in range(len(raw_promis_files)):\n",
    "        readable_promis_file = ((str(raw_promis_files[i])).replace('\\\\','/')) # converts all survey files into inputtable format\n",
    "        df = pd.read_json(readable_promis_file)\n",
    "        temp_daily_arr = []\n",
    "        if 'DailyFatigue_1Item' in df['answers'] and 'key' in df.columns:\n",
    "            temp_daily_arr.append(str(readable_promis_file)[72:104])\n",
    "            temp_daily_arr.append(int(str(df['key'])[27:29])) # month\n",
    "            temp_daily_arr.append(int(str(df['key'])[30:32])) # day\n",
    "            temp_daily_arr.append(df['answers']['DailyFatigue_1Item'])\n",
    "            daily_promis_files.append(temp_daily_arr)\n",
    "            temp_daily_arr = []\n",
    "    return daily_promis_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d3043818-32dc-44e4-a775-69a80a6aaf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing\n",
    "\n",
    "df = pd.DataFrame(np.vstack(compile_fatigue(r\"C:\\Users\\VictoriaAgain\\Downloads\\surveys-20250613T020413Z-1-001\\surveys\")),columns=['patient_id','month','day','promis_score'])\n",
    "df.to_csv('combined_promis_scores.csv',index=False,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "261310a3-a7be-463b-96f3-1a940a75f200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparing both average heartrate and promis score files\n",
    "# given both files, find where dates (unix time to month + date) match up and patient_id matches\n",
    "# add all information to new combined csv file\n",
    "\n",
    "df_hr = pd.read_csv('combined_files_avg_hr.csv')\n",
    "df_promis = pd.read_csv('combined_promis_scores.csv')\n",
    "\n",
    "# convert timestamp to datetime and extract month + day\n",
    "df_hr['datetime'] = pd.to_datetime(df_hr['timestamp'], unit='s')\n",
    "df_hr['month'] = df_hr['datetime'].dt.month\n",
    "df_hr['day'] = df_hr['datetime'].dt.day\n",
    "\n",
    "# filter cols\n",
    "df_hr_filtered = df_hr[['patient_id', 'month', 'day', 'average_hr', 'steps']]\n",
    "\n",
    "# merge dfs on patient_id, month, and day\n",
    "df_merged = pd.merge(df_promis, df_hr_filtered,\n",
    "                     on = ['patient_id', 'month', 'day'],\n",
    "                     how = 'inner')\n",
    "\n",
    "df_final = df_merged[['patient_id', 'month', 'day', 'average_hr', 'steps', 'promis_score']]\n",
    "df_final.columns = ['patient id', 'month', 'day', 'heartrate', 'steps', 'promis score']\n",
    "\n",
    "df_final.to_csv('final_avg_hr_data_updated.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f817a1e-2d06-4cb2-9249-317e65bca411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting promis scores to numerical values\n",
    "\n",
    "def compile_fatigue_numbers(folder_path):\n",
    "    p = Path(folder_path)\n",
    "    raw_promis_files = list(p.rglob('*.json*')) # all json files\n",
    "    daily_promis_numbers = []\n",
    "    \n",
    "    for i in range(len(raw_promis_files)):\n",
    "        readable_promis_file = ((str(raw_promis_files[i])).replace('\\\\','/')) # converts all survey files into inputtable format\n",
    "        df = pd.read_json(readable_promis_file)\n",
    "        temp_daily_arr = []\n",
    "        if 'DailyFatigue_1Item' in df['answers'] and 'key' in df.columns:\n",
    "            temp_daily_arr.append(str(readable_promis_file)[72:104])\n",
    "            temp_daily_arr.append(int(str(df['key'])[27:29])) # month\n",
    "            temp_daily_arr.append(int(str(df['key'])[30:32])) # day\n",
    "            promis_score = df['answers']['DailyFatigue_1Item']\n",
    "            if promis_score == 'Not fatigued at all':\n",
    "                temp_daily_arr.append(0)\n",
    "            elif promis_score == 'A little bit fatigued':\n",
    "                temp_daily_arr.append(1)\n",
    "            elif promis_score == 'Somewhat fatigued':\n",
    "                temp_daily_arr.append(2)\n",
    "            elif promis_score == 'Very fatigued':\n",
    "                temp_daily_arr.append(3)\n",
    "            daily_promis_numbers.append(temp_daily_arr)\n",
    "            temp_daily_arr = []\n",
    "    return daily_promis_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a40da94-c6f5-4137-a4bf-49be9cf35805",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.vstack(compile_fatigue_numbers(r\"C:\\Users\\VictoriaAgain\\Downloads\\surveys-20250613T020413Z-1-001\\surveys\")),columns=['patient_id','month','day','promis_score'])\n",
    "df.to_csv('combined_promis_nums.csv',index=False,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "855cad90-d27c-4f8f-86cd-14c5967ab0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hr = pd.read_csv('combined_files_avg_hr.csv')\n",
    "df_promis = pd.read_csv('combined_promis_nums.csv')\n",
    "\n",
    "# convert timestamp to datetime and extract month + day\n",
    "df_hr['datetime'] = pd.to_datetime(df_hr['timestamp'], unit='s')\n",
    "df_hr['month'] = df_hr['datetime'].dt.month\n",
    "df_hr['day'] = df_hr['datetime'].dt.day\n",
    "\n",
    "# filter cols\n",
    "df_hr_filtered = df_hr[['patient_id', 'month', 'day', 'average_hr', 'steps']]\n",
    "\n",
    "# merge dfs on patient_id, month, and day\n",
    "df_merged = pd.merge(df_promis, df_hr_filtered,\n",
    "                     on = ['patient_id', 'month', 'day'],\n",
    "                     how = 'inner')\n",
    "\n",
    "df_final = df_merged[['patient_id', 'month', 'day', 'average_hr', 'steps', 'promis_score']]\n",
    "df_final.columns = ['patient id', 'month', 'day', 'heartrate', 'steps', 'promis score']\n",
    "\n",
    "df_final.to_csv('final_avg_hr_nums_updated.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "406e15e5-f177-4d8f-98f9-8586496d3f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%git` not found.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8663f7-3e19-4794-93df-c10a2b8759af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
