{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "533974aa-77d3-4d5a-b056-9a93cd6607cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from pathlib import Path\n",
    "from collections import namedtuple\n",
    "from datetime import datetime\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from zoneinfo import ZoneInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecb31141-e3cc-48b9-9ee0-c5a505705c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking the average heart rate of each day for a patient\n",
    "# make an array that has patient id, average heart rate, day\n",
    "# given an input of the total patient heart rate csv file\n",
    "\n",
    "# ISSUE -- missing some days ?\n",
    "\n",
    "def timestamp_avg_hr(csv_file):\n",
    "    list_avg_hr = []\n",
    "    list_day_hr = []\n",
    "    \n",
    "    df = pd.read_csv(csv_file) # csv into dataframe\n",
    "\n",
    "    if df.empty or 'timestamp' not in df.columns or 'heartrate' not in df.columns:\n",
    "        return [],[]\n",
    "        \n",
    "    unix_prev = df['timestamp'].loc[0]\n",
    "    temp_day_prev = datetime.fromtimestamp(df['timestamp'].loc[0],tz=ZoneInfo(\"America/New_York\")).day # first day\n",
    "    temp_hr_sum = 0\n",
    "    counter = 0\n",
    "\n",
    "    for i in range(1,len(df)): # iterates through each row\n",
    "        val = df['timestamp'].loc[i] # the timestamp value at that row\n",
    "        temp_day_curr = datetime.fromtimestamp(val,tz=ZoneInfo(\"America/New_York\")).day # converting to # date\n",
    "        if temp_day_prev == temp_day_curr:\n",
    "            counter += 1\n",
    "            temp_hr_sum += df['heartrate'].loc[i]\n",
    "        elif temp_day_curr != temp_day_prev:\n",
    "            if (counter != 0):\n",
    "                list_day_hr.append(unix_prev) # add day to list\n",
    "                avg_hr = temp_hr_sum/counter\n",
    "                list_avg_hr.append(avg_hr)\n",
    "                \n",
    "            temp_hr_sum = 0\n",
    "            counter = 1\n",
    "                \n",
    "            unix_prev = df['timestamp'].loc[i]\n",
    "            temp_day_prev = temp_day_curr\n",
    "\n",
    "    # for last day otherwise not included\n",
    "    if (counter != 0):\n",
    "        unix_prev = df['timestamp'].loc[len(df.index)-1]\n",
    "        list_day_hr.append(unix_prev)\n",
    "        avg_hr = temp_hr_sum/counter\n",
    "        list_avg_hr.append(avg_hr)\n",
    "            \n",
    "    return list_avg_hr, list_day_hr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "c463b993-6cef-4f6a-8117-e7b382324e0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[61.40504240989685,\n",
       " 58.65889990790773,\n",
       " 62.746314953535034,\n",
       " 62.41864027056778,\n",
       " 63.21909400563181,\n",
       " 63.87911976342914,\n",
       " 61.25889745407556,\n",
       " 59.62554954302193,\n",
       " 66.04216952945875,\n",
       " 60.50209519357392,\n",
       " 62.001353803362164,\n",
       " 61.24506235122681,\n",
       " 60.829745292663574,\n",
       " 65.9012573099582,\n",
       " 62.900367736816406,\n",
       " 59.51804539414703,\n",
       " 62.77773554913409,\n",
       " 65.72451510095293,\n",
       " 58.908621686570186,\n",
       " 62.790159986318784,\n",
       " 63.84863236662629,\n",
       " 63.53794591741045,\n",
       " 67.7548113472854,\n",
       " 68.09921374601477,\n",
       " 63.367909582037676,\n",
       " 63.226089566667504,\n",
       " 64.43308039745652,\n",
       " 66.51823991537094,\n",
       " 62.2603399525518,\n",
       " 65.4703304270372,\n",
       " 68.35044422368894,\n",
       " 68.07132471222238,\n",
       " 64.95731658935547,\n",
       " 61.863194024002794,\n",
       " 63.811128338178,\n",
       " 65.8810852547369,\n",
       " 65.79501162700771,\n",
       " 65.04408445261946,\n",
       " 59.719052115152046,\n",
       " 60.477233605635796,\n",
       " 62.582818173571845,\n",
       " 60.47944512574569,\n",
       " 59.52857790046564,\n",
       " 61.939821811822746,\n",
       " 61.74594856710995,\n",
       " 59.288617485447936,\n",
       " 63.38245942321005,\n",
       " 58.80526784125795,\n",
       " 60.049002475875746,\n",
       " 64.82713074154324,\n",
       " 60.03616735035788,\n",
       " 59.54697264157809,\n",
       " 60.38627578333804,\n",
       " 63.68238686168261,\n",
       " 57.23163096110026,\n",
       " 59.084879449073306,\n",
       " 62.05267971001783,\n",
       " 63.77550487830991,\n",
       " 59.83616503829476,\n",
       " 63.215016382821595,\n",
       " 61.84897948234312,\n",
       " 54.423498171512215,\n",
       " 58.3917573408647,\n",
       " 60.29257246318616,\n",
       " 57.11016877492269,\n",
       " 64.0450805858442,\n",
       " 61.52727210100959,\n",
       " 60.651639010455156,\n",
       " 61.40015207018171,\n",
       " 58.897311528523765,\n",
       " 65.41558895279876,\n",
       " 60.04558340984842,\n",
       " 59.8208310094373,\n",
       " 57.96373257871534,\n",
       " 58.87148648883225,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 76.72267999106306,\n",
       " 60.84921810295008,\n",
       " 61.263306975364685,\n",
       " 46.0,\n",
       " 60.14310362603929,\n",
       " 63.23790369751633,\n",
       " 58.4499075124552,\n",
       " 71.57897865772247,\n",
       " 60.772902356661284,\n",
       " 76.46198191732731,\n",
       " 62.48218320363976,\n",
       " 60.160893519280364,\n",
       " 60.37424106597901,\n",
       " 58.80793136804282,\n",
       " 62.67223708901629,\n",
       " 62.00458844502767,\n",
       " 65.29447239406859,\n",
       " 60.28192700214267,\n",
       " 61.64096273052755,\n",
       " 72.84724746575336,\n",
       " 61.82381398560571,\n",
       " 70.06818686832081,\n",
       " 64.41730936562142,\n",
       " 59.65038886437049]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing heartrate nums\n",
    "\n",
    "from zoneinfo import ZoneInfo\n",
    "\n",
    "list_avg_hr,list_day_hr = timestamp_avg_hr(r\"C:\\Users\\VictoriaAgain\\Downloads\\download\\76b7b72800f5590dc4cb02f90ddcf42a\\combined_heartrate.csv\")\n",
    "\n",
    "# list_avg_hr = np.array(list_avg_hr)\n",
    "# # x_array = np.array([2,3,5,6,7,4,8,7,6])\n",
    "\n",
    "# type(list_avg_hr)\n",
    "# datelist = []\n",
    "# for i in range(len(list_day_hr)):\n",
    "#     date = datetime.fromtimestamp(list_day_hr[i],tz=ZoneInfo(\"America/New_York\")).date()\n",
    "#     print(date)\n",
    "#     datelist.append(date)\n",
    "\n",
    "# print(len(datelist))\n",
    "# print(len(list_day_hr), len(list_avg_hr))\n",
    "# print(len(list_day_hr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a19b138a-a61e-4abb-a31d-f553b2e23274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total steps by day for one patient given csv file path\n",
    "\n",
    "def timestamp_total_step(csv_file):\n",
    "    list_total_step = []\n",
    "    list_day_step = []\n",
    "    \n",
    "    df = pd.read_csv(csv_file)\n",
    "\n",
    "    if df.empty or 'stop' not in df.columns or 'steps' not in df.columns:\n",
    "        return [],[]\n",
    "    \n",
    "    unix_prev = df['stop'].loc[0]\n",
    "    temp_day_prev = datetime.fromtimestamp(df['stop'].loc[0]).day\n",
    "    temp_total_step = 0\n",
    "    \n",
    "    for i in df.index:\n",
    "        val = df['stop'].loc[i]\n",
    "        temp_day_curr = datetime.fromtimestamp(val).day\n",
    "        if temp_day_prev == temp_day_curr:\n",
    "            temp_total_step += df['steps'].loc[i]\n",
    "        elif temp_day_curr != temp_day_prev:\n",
    "            list_day_step.append(unix_prev)\n",
    "            list_total_step.append(temp_total_step)\n",
    "            unix_prev = df['stop'].loc[i]\n",
    "            temp_total_step = 0\n",
    "            temp_day_prev = temp_day_curr\n",
    "\n",
    "    # for last day otherwise not included\n",
    "    unix_prev = df['stop'].loc[len(df.index)-1]\n",
    "    list_day_step.append(unix_prev)\n",
    "    list_total_step.append(temp_total_step)\n",
    "    \n",
    "    return list_total_step, list_day_step\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "8f581407-1343-49c1-a912-6d2d9d5dcd24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing\n",
    "step,day = timestamp_total_step(r\"C:\\Users\\VictoriaAgain\\Downloads\\download\\c87141d67c53c9415a4402e46522313c\\combined_steps.csv\")\n",
    "step\n",
    "# datelist = []\n",
    "# for i in range(len(day)):\n",
    "#     date = datetime.fromtimestamp(list_day_hr[i],tz=ZoneInfo(\"America/New_York\")).date()\n",
    "#     print(date)\n",
    "    # datelist.append(date)\n",
    "# print(datelist)\n",
    "# df = pd.read_csv(r\"C:\\Users\\VictoriaAgain\\Downloads\\download\\90b8c2e2c843ffd77f8621c7d6ed044d\\combined_steps.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "cf89b264-9241-4d01-bc79-5de7c7155968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing heartrate and steps for each patient before merging lists\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def norm_data(hr, step):\n",
    "    hr = np.array(hr)\n",
    "    step = np.array(step)\n",
    "\n",
    "    standard_hr, standard_step = [], []\n",
    "\n",
    "    if (hr.size > 0 and step.size > 0):\n",
    "        # sklearn normalization\n",
    "        norm_hr = preprocessing.normalize(hr.reshape(-1,1))\n",
    "        norm_step = preprocessing.normalize(step.reshape(-1,1))\n",
    "    \n",
    "        # using minmaxscaler\n",
    "        scaler_hr = preprocessing.MinMaxScaler(feature_range=(0,10))\n",
    "        scaler_step = preprocessing.MinMaxScaler(feature_range=(0,10))\n",
    "        minmax_hr = scaler_hr.fit_transform(hr.reshape(-1,1))\n",
    "        minmax_step = scaler_step.fit_transform(step.reshape(-1,1))\n",
    "    \n",
    "        # using zscore norm/standardization\n",
    "        z_scaler_hr = StandardScaler()\n",
    "        z_scaler_step = StandardScaler()\n",
    "        standard_hr = z_scaler_hr.fit_transform(hr.reshape(-1,1))\n",
    "        standard_step = z_scaler_step.fit_transform(step.reshape(-1,1))\n",
    "    \n",
    "    return(standard_hr, standard_step)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7228e2-0080-4b96-85ca-5fa152f145d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing normalization\n",
    "step_arr, step_day = timestamp_total_step(r\"C:\\Users\\VictoriaAgain\\Downloads\\download\\9b7f67d9f8d32605492cfa1c7282d35a\\combined_steps.csv\")\n",
    "hr_arr, hr_day = timestamp_avg_hr(r\"C:\\Users\\VictoriaAgain\\Downloads\\download\\9b7f67d9f8d32605492cfa1c7282d35a\\combined_heartrate.csv\")\n",
    "standard_hr, standard_step = norm_data(hr_arr,step_arr)\n",
    "standard_hr\n",
    "# type(standard_hr)\n",
    "# standard_hr = standard_hr.flatten()\n",
    "# df = pd.DataFrame(standard_hr)\n",
    "# df.head(50)\n",
    "# df_step = pd.DataFrame(step)\n",
    "# hr, step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "cbda3f10-eee4-4a84-9531-2954b471950d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining heart rate and step files for each patient\n",
    "# given the day is the same -- check month and day are the same, create new 2d array with same date and corresponding heart rate + steps\n",
    "# also return patient id via substring\n",
    "\n",
    "def compile_step_hr(hr_file,step_file):\n",
    "    step_arr, step_day = timestamp_total_step(step_file)\n",
    "    hr_arr, hr_day = timestamp_avg_hr(hr_file)\n",
    "\n",
    "    hr_arr, step_arr = norm_data(hr_arr, step_arr) # will produce 2 empty arrays if there are faulty files\n",
    "    combined_arr = []\n",
    "\n",
    "    if (len(hr_arr) > 0 and len(step_arr) > 0):\n",
    "        step_arr = step_arr.flatten()\n",
    "        hr_arr = hr_arr.flatten()\n",
    "        \n",
    "        list_day = []\n",
    "        list_hr = []\n",
    "        list_step = []\n",
    "    \n",
    "        for i in range(np.minimum(len(hr_day),len(step_day))):  # whichever is smaller\n",
    "            hr_date = datetime.fromtimestamp(hr_day[i]).date()\n",
    "            step_date = datetime.fromtimestamp(step_day[i]).date()\n",
    "    \n",
    "            if hr_date == step_date:\n",
    "                list_day.append(hr_day[i])\n",
    "                list_hr.append(hr_arr[i])\n",
    "                list_step.append(step_arr[i])\n",
    "            elif hr_date > step_date:\n",
    "                for j in range(i,len(step_day)):\n",
    "                    if datetime.fromtimestamp(step_day[j], tz=ZoneInfo(\"America/New_York\")).date() == hr_date:\n",
    "                        list_day.append(hr_day[i])\n",
    "                        list_hr.append(hr_arr[i])\n",
    "                        list_step.append(step_arr[j])\n",
    "            elif (step_date > hr_date): # step day skips, go through rest of heart rate days\n",
    "                for k in range(i,len(hr_day)):\n",
    "                    if datetime.fromtimestamp(hr_day[k], tz=ZoneInfo(\"America/New_York\")).date() == step_date:\n",
    "                        list_day.append(hr_day[k])\n",
    "                        list_hr.append(hr_arr[k])\n",
    "                        list_step.append(step_arr[i])\n",
    "        \n",
    "        list_patient_id = [str(hr_file)[42:74]]*len(list_day)\n",
    "        combined_arr = np.column_stack((list_patient_id,list_day,list_hr,list_step))\n",
    "    return combined_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "f8434a47-2066-4ac8-9334-675eadd789fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing\n",
    "\n",
    "# taking array and turning into csv file\n",
    "arr = compile_step_hr(r\"C:\\Users\\VictoriaAgain\\Downloads\\download\\76b7b72800f5590dc4cb02f90ddcf42a\\combined_heartrate.csv\",r\"C:\\Users\\VictoriaAgain\\Downloads\\download\\76b7b72800f5590dc4cb02f90ddcf42a\\combined_steps.csv\")\n",
    "# arr = compile_step_hr(r\"C:\\Users\\VictoriaAgain\\Downloads\\download\\90b8c2e2c843ffd77f8621c7d6ed044d\\combined_heartrate.csv\",r\"C:\\Users\\VictoriaAgain\\Downloads\\download\\90b8c2e2c843ffd77f8621c7d6ed044d\\combined_steps.csv\")\n",
    "\n",
    "df = pd.DataFrame(arr)\n",
    "df\n",
    "# patient_id time hr step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "e6203f1b-d6a3-414a-876c-ac44ce3ac2ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# given a folder go through each of the folders and create an array based on the combined heartrate and steps\n",
    "\n",
    "# ISSUE -- normalizing data not working for files? \n",
    "# 2 patients didn't have recorded step trackers, add in clause to prevent normalizing function if arr is empty\n",
    "p = Path(\"C:/Users/VictoriaAgain/Downloads/download\")\n",
    "raw_files = list(p.rglob('*.csv*')) # returns list of all csv files within the download folder\n",
    "files = []\n",
    "all_files = []\n",
    "\n",
    "for i in range(len(raw_files)): # list of machine readable file names in order\n",
    "    files.append(str(raw_files[i]).replace('\\\\','/'))\n",
    "for j in range(0,len(files)-1,2):\n",
    "    combined_file = compile_step_hr(files[j],files[j+1])\n",
    "    if (len(combined_file) > 0):\n",
    "        all_files.append(combined_file)\n",
    "\n",
    "final_df = pd.DataFrame(np.vstack(all_files),columns=['patient_id','timestamp','average heartrate','steps'])\n",
    "final_df\n",
    "final_df.to_csv('combined_avg_hr_NORM.csv',index=False,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d74efe50-36d0-48ff-873c-87e0583ec11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at different classification models!!\n",
    "# sk learn package -- regression tracking, classification -- try and use classifier!\n",
    "\n",
    "# new function -- go through all of the folders and json files, create a csv file with all of the daily PROMIS responses, days, and patient_id\n",
    "# if json file has daily faigue 1 item, put patient_id, promis score, and date in big csv file\n",
    "# go through both hr_step and promis_file, combined based on dates and patient_id\n",
    "\n",
    "def compile_fatigue(folder_path):\n",
    "    p = Path(folder_path)\n",
    "    raw_promis_files = list(p.rglob('*.json*')) # all json files\n",
    "    daily_promis_files = []\n",
    "    \n",
    "    for i in range(len(raw_promis_files)):\n",
    "        readable_promis_file = ((str(raw_promis_files[i])).replace('\\\\','/')) # converts all survey files into inputtable format\n",
    "        df = pd.read_json(readable_promis_file)\n",
    "        temp_daily_arr = []\n",
    "        if 'DailyFatigue_1Item' in df['answers'] and 'key' in df.columns:\n",
    "            temp_daily_arr.append(str(readable_promis_file)[72:104])\n",
    "            temp_daily_arr.append(int(str(df['key'])[27:29])) # month\n",
    "            temp_daily_arr.append(int(str(df['key'])[30:32])) # day\n",
    "            temp_daily_arr.append(df['answers']['DailyFatigue_1Item'])\n",
    "            daily_promis_files.append(temp_daily_arr)\n",
    "            temp_daily_arr = []\n",
    "    return daily_promis_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d3043818-32dc-44e4-a775-69a80a6aaf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing\n",
    "\n",
    "df = pd.DataFrame(np.vstack(compile_fatigue(r\"C:\\Users\\VictoriaAgain\\Downloads\\surveys-20250613T020413Z-1-001\\surveys\")),columns=['patient_id','month','day','promis_score'])\n",
    "df.to_csv('combined_promis_scores.csv',index=False,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "261310a3-a7be-463b-96f3-1a940a75f200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparing both average heartrate and promis score files\n",
    "# given both files, find where dates (unix time to month + date) match up and patient_id matches\n",
    "# add all information to new combined csv file\n",
    "\n",
    "df_hr = pd.read_csv('combined_files_avg_hr.csv')\n",
    "df_promis = pd.read_csv('combined_promis_scores.csv')\n",
    "\n",
    "# convert timestamp to datetime and extract month + day\n",
    "df_hr['datetime'] = pd.to_datetime(df_hr['timestamp'], unit='s')\n",
    "df_hr['month'] = df_hr['datetime'].dt.month\n",
    "df_hr['day'] = df_hr['datetime'].dt.day\n",
    "\n",
    "# filter cols\n",
    "df_hr_filtered = df_hr[['patient_id', 'month', 'day', 'average_hr', 'steps']]\n",
    "\n",
    "# merge dfs on patient_id, month, and day\n",
    "df_merged = pd.merge(df_promis, df_hr_filtered,\n",
    "                     on = ['patient_id', 'month', 'day'],\n",
    "                     how = 'inner')\n",
    "\n",
    "df_final = df_merged[['patient_id', 'month', 'day', 'average_hr', 'steps', 'promis_score']]\n",
    "df_final.columns = ['patient id', 'month', 'day', 'heartrate', 'steps', 'promis score']\n",
    "\n",
    "df_final.to_csv('final_avg_hr_data_updated.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f817a1e-2d06-4cb2-9249-317e65bca411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting promis scores to numerical values\n",
    "\n",
    "def compile_fatigue_numbers(folder_path):\n",
    "    p = Path(folder_path)\n",
    "    raw_promis_files = list(p.rglob('*.json*')) # all json files\n",
    "    daily_promis_numbers = []\n",
    "    \n",
    "    for i in range(len(raw_promis_files)):\n",
    "        readable_promis_file = ((str(raw_promis_files[i])).replace('\\\\','/')) # converts all survey files into inputtable format\n",
    "        df = pd.read_json(readable_promis_file)\n",
    "        temp_daily_arr = []\n",
    "        if 'DailyFatigue_1Item' in df['answers'] and 'key' in df.columns:\n",
    "            temp_daily_arr.append(str(readable_promis_file)[72:104])\n",
    "            temp_daily_arr.append(int(str(df['key'])[27:29])) # month\n",
    "            temp_daily_arr.append(int(str(df['key'])[30:32])) # day\n",
    "            promis_score = df['answers']['DailyFatigue_1Item']\n",
    "            if promis_score == 'Not fatigued at all':\n",
    "                temp_daily_arr.append(0)\n",
    "            elif promis_score == 'A little bit fatigued':\n",
    "                temp_daily_arr.append(1)\n",
    "            elif promis_score == 'Somewhat fatigued':\n",
    "                temp_daily_arr.append(2)\n",
    "            elif promis_score == 'Very fatigued':\n",
    "                temp_daily_arr.append(3)\n",
    "            daily_promis_numbers.append(temp_daily_arr)\n",
    "            temp_daily_arr = []\n",
    "    return daily_promis_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a40da94-c6f5-4137-a4bf-49be9cf35805",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.vstack(compile_fatigue_numbers(r\"C:\\Users\\VictoriaAgain\\Downloads\\surveys-20250613T020413Z-1-001\\surveys\")),columns=['patient_id','month','day','promis_score'])\n",
    "df.to_csv('combined_promis_nums.csv',index=False,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "855cad90-d27c-4f8f-86cd-14c5967ab0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hr = pd.read_csv('combined_files_avg_hr.csv')\n",
    "df_promis = pd.read_csv('combined_promis_nums.csv')\n",
    "\n",
    "# convert timestamp to datetime and extract month + day\n",
    "df_hr['datetime'] = pd.to_datetime(df_hr['timestamp'], unit='s')\n",
    "df_hr['month'] = df_hr['datetime'].dt.month\n",
    "df_hr['day'] = df_hr['datetime'].dt.day\n",
    "\n",
    "# filter cols\n",
    "df_hr_filtered = df_hr[['patient_id', 'month', 'day', 'average_hr', 'steps']]\n",
    "\n",
    "# merge dfs on patient_id, month, and day\n",
    "df_merged = pd.merge(df_promis, df_hr_filtered,\n",
    "                     on = ['patient_id', 'month', 'day'],\n",
    "                     how = 'inner')\n",
    "\n",
    "df_final = df_merged[['patient_id', 'month', 'day', 'average_hr', 'steps', 'promis_score']]\n",
    "df_final.columns = ['patient id', 'month', 'day', 'heartrate', 'steps', 'promis score']\n",
    "\n",
    "df_final.to_csv('final_avg_hr_nums_updated.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8663f7-3e19-4794-93df-c10a2b8759af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
