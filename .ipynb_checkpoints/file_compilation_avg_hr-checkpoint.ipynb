{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "533974aa-77d3-4d5a-b056-9a93cd6607cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from pathlib import Path\n",
    "from collections import namedtuple\n",
    "from datetime import datetime\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from zoneinfo import ZoneInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ecb31141-e3cc-48b9-9ee0-c5a505705c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking the average heart rate of each day for a patient\n",
    "# make an array that has patient id, average heart rate, day\n",
    "# given an input of the total patient heart rate csv file\n",
    "\n",
    "# ISSUE -- missing some days ?\n",
    "\n",
    "def timestamp_avg_hr(csv_file):\n",
    "    list_avg_hr = []\n",
    "    list_day_hr = []\n",
    "    \n",
    "    df = pd.read_csv(csv_file) # csv into dataframe\n",
    "\n",
    "    if df.empty or 'timestamp' not in df.columns or 'heartrate' not in df.columns:\n",
    "        return [],[]\n",
    "        \n",
    "    unix_prev = df['timestamp'].loc[0]\n",
    "    temp_day_prev = datetime.fromtimestamp(df['timestamp'].loc[0],tz=ZoneInfo(\"America/New_York\")).day # first day\n",
    "    temp_hr_sum = 0\n",
    "    counter = 0\n",
    "\n",
    "    for i in range(1,len(df)): # iterates through each row\n",
    "        val = df['timestamp'].loc[i] # the timestamp value at that row\n",
    "        temp_day_curr = datetime.fromtimestamp(val,tz=ZoneInfo(\"America/New_York\")).day # converting to # date\n",
    "        if temp_day_prev == temp_day_curr:\n",
    "            counter += 1\n",
    "            temp_hr_sum += df['heartrate'].loc[i]\n",
    "        elif temp_day_curr != temp_day_prev:\n",
    "            if (counter != 0):\n",
    "                list_day_hr.append(unix_prev) # add day to list\n",
    "                avg_hr = temp_hr_sum/counter\n",
    "                list_avg_hr.append(avg_hr)\n",
    "                \n",
    "            temp_hr_sum = 0\n",
    "            counter = 1\n",
    "                \n",
    "            unix_prev = df['timestamp'].loc[i]\n",
    "            temp_day_prev = temp_day_curr\n",
    "\n",
    "    # for last day otherwise not included\n",
    "    if (counter != 0):\n",
    "        unix_prev = df['timestamp'].loc[len(df.index)-1]\n",
    "        list_day_hr.append(unix_prev)\n",
    "        avg_hr = temp_hr_sum/counter\n",
    "        list_avg_hr.append(avg_hr)\n",
    "            \n",
    "    return list_avg_hr, list_day_hr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c463b993-6cef-4f6a-8117-e7b382324e0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing heartrate nums\n",
    "\n",
    "from zoneinfo import ZoneInfo\n",
    "\n",
    "list_avg_hr,list_day_hr = timestamp_avg_hr(r\"C:\\Users\\VictoriaAgain\\Downloads\\download\\80929938f623f44614a029108a740d00\\combined_heartrate.csv\")\n",
    "\n",
    "\n",
    "list_avg_hr = np.array(list_avg_hr)\n",
    "# x_array = np.array([2,3,5,6,7,4,8,7,6])\n",
    "\n",
    "type(list_avg_hr)\n",
    "# datelist = []\n",
    "# for i in range(len(list_day_hr)):\n",
    "#     date = datetime.fromtimestamp(list_day_hr[i],tz=ZoneInfo(\"America/New_York\")).date()\n",
    "#     print(date)\n",
    "#     datelist.append(date)\n",
    "\n",
    "# print(len(datelist))\n",
    "# print(len(list_day_hr), len(list_avg_hr))\n",
    "# print(len(list_day_hr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a19b138a-a61e-4abb-a31d-f553b2e23274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total steps by day for one patient given csv file path\n",
    "\n",
    "def timestamp_total_step(csv_file):\n",
    "    list_total_step = []\n",
    "    list_day_step = []\n",
    "    \n",
    "    df = pd.read_csv(csv_file)\n",
    "\n",
    "    if df.empty or 'stop' not in df.columns or 'steps' not in df.columns:\n",
    "        return [],[]\n",
    "    \n",
    "    unix_prev = df['stop'].loc[0]\n",
    "    temp_day_prev = datetime.fromtimestamp(df['stop'].loc[0]).day\n",
    "    temp_total_step = 0\n",
    "    \n",
    "    for i in df.index:\n",
    "        val = df['stop'].loc[i]\n",
    "        temp_day_curr = datetime.fromtimestamp(val).day\n",
    "        if temp_day_prev == temp_day_curr:\n",
    "            temp_total_step += df['steps'].loc[i]\n",
    "        elif temp_day_curr != temp_day_prev:\n",
    "            list_day_step.append(unix_prev)\n",
    "            list_total_step.append(temp_total_step)\n",
    "            unix_prev = df['stop'].loc[i]\n",
    "            temp_total_step = 0\n",
    "            temp_day_prev = temp_day_curr\n",
    "\n",
    "    # for last day otherwise not included\n",
    "    unix_prev = df['stop'].loc[len(df.index)-1]\n",
    "    list_day_step.append(unix_prev)\n",
    "    list_total_step.append(temp_total_step)\n",
    "    \n",
    "    return list_total_step, list_day_step\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f581407-1343-49c1-a912-6d2d9d5dcd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing\n",
    "step,day = timestamp_total_step(r\"C:\\Users\\VictoriaAgain\\Downloads\\download\\80929938f623f44614a029108a740d00\\combined_steps.csv\")\n",
    "step\n",
    "# datelist = []\n",
    "# for i in range(len(day)):\n",
    "#     date = datetime.fromtimestamp(list_day_hr[i],tz=ZoneInfo(\"America/New_York\")).date()\n",
    "#     print(date)\n",
    "    # datelist.append(date)\n",
    "# print(datelist)\n",
    "# df = pd.read_csv(r\"C:\\Users\\VictoriaAgain\\Downloads\\download\\90b8c2e2c843ffd77f8621c7d6ed044d\\combined_steps.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "cf89b264-9241-4d01-bc79-5de7c7155968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing heartrate and steps for each patient before merging lists\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def norm_data(hr_file,step_file):\n",
    "    hr, hr_day = timestamp_avg_hr(hr_file)\n",
    "    step, step_day = timestamp_total_step(step_file)\n",
    "\n",
    "    hr = np.array(hr)\n",
    "    step = np.array(step)\n",
    "    \n",
    "    norm_hr = preprocessing.normalize([hr])\n",
    "    norm_step = preprocessing.normalize([step])\n",
    "\n",
    "    # using minmaxscaler\n",
    "    scaler = preprocessing.MinMaxScaler(feature_range=(0,10))\n",
    "    scale_hr = scaler.fit_transform(hr.reshape(-1,1))\n",
    "    scale_step = scaler.fit_transform(step.reshape(-1,1))\n",
    "    \n",
    "    return(norm_hr, norm_step,scale_hr,scale_step)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b2fc46e7-5483-42d9-885c-03682b45c6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing again\n",
    "hr, hr_day = timestamp_avg_hr(r\"C:\\Users\\VictoriaAgain\\Downloads\\download\\80929938f623f44614a029108a740d00\\combined_heartrate.csv\")\n",
    "step, step_day = timestamp_total_step(r\"C:\\Users\\VictoriaAgain\\Downloads\\download\\80929938f623f44614a029108a740d00\\combined_steps.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "9c7228e2-0080-4b96-85ca-5fa152f145d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.20091194e-03 2.50622588e-04 9.91749382e-03 5.05409634e-02\n",
      " 1.94051109e-02 1.88726101e-02 8.36677170e-04 0.00000000e+00\n",
      " 3.28475015e-02 1.54177937e-02 2.26753770e-04 4.47359255e-03\n",
      " 3.35930757e-02 4.32250110e-03 4.90026831e-02 5.80494490e-02\n",
      " 8.45038990e-02 2.69598298e-02 1.01393246e-01 5.26443810e-03\n",
      " 4.55894421e-02 1.87778356e-02 3.77523383e-02 1.09036044e-01\n",
      " 5.81463381e-02 2.79530545e-02 2.52293405e-02 3.58032268e-05\n",
      " 7.92444753e-03 3.52020876e-02 6.98162923e-03 2.23693906e-02\n",
      " 7.64067553e-02 6.24409061e-02 3.60858440e-02 1.61114521e-02\n",
      " 7.97637338e-02 1.31206700e-01 7.89714591e-02 9.90555941e-04\n",
      " 3.73095132e-02 6.60321735e-02 1.18515659e-01 6.79680083e-02\n",
      " 8.96224581e-02 2.99397665e-02 5.54353295e-02 5.78699489e-02\n",
      " 4.42246717e-02 7.51093259e-02 9.14423451e-02 9.45257416e-02\n",
      " 6.52928919e-02 4.87520605e-02 3.61598620e-02 7.49116368e-02\n",
      " 4.06055306e-02 3.38805181e-02 3.12203537e-02 2.75406540e-02\n",
      " 5.33483100e-02 7.53793099e-02 2.97194680e-02 4.53171268e-02\n",
      " 3.67770672e-02 4.05687793e-02 1.05964790e-01 4.13571207e-02\n",
      " 9.05890977e-02 3.11965450e-02 3.55351230e-02 8.94484751e-02\n",
      " 9.99817892e-02 6.75845578e-02 9.25036036e-02 6.87580662e-02\n",
      " 3.65550946e-02 7.80364429e-02 9.11486829e-02 7.83718746e-02\n",
      " 9.10322869e-02 1.51025997e-01 2.45932646e-02 8.61280678e-02\n",
      " 1.10688204e-01 1.25299093e-01 7.63563484e-02 8.01872936e-02\n",
      " 3.87725076e-02 7.49056122e-02 1.04828869e-01 9.80531038e-02\n",
      " 1.56651052e-01 1.71798019e-01 1.12059551e-01 1.19089908e-01\n",
      " 7.24472629e-02 7.39683461e-02 9.90078565e-02 1.02289819e-01\n",
      " 1.02106299e-01 2.05391178e-02 1.52001993e-01 5.12821552e-02\n",
      " 2.92159671e-02 1.33466169e-01 1.00337764e-01 9.49426683e-02\n",
      " 9.83310480e-02 8.75985616e-02 1.42189980e-01 4.60675008e-02\n",
      " 5.10792702e-02 9.45562253e-02 1.07167465e-01 8.50350505e-02\n",
      " 7.81465097e-02 1.08830404e-01 3.30317132e-02 6.79561515e-02\n",
      " 1.27278415e-01 7.83464157e-02 9.13817692e-02 2.42133905e-02\n",
      " 8.54796621e-02 3.46813924e-02 1.22683144e-01 8.67841526e-02\n",
      " 1.03909641e-01 1.38258035e-01 1.44181419e-01 3.67460451e-02\n",
      " 5.71658188e-02 8.05811291e-02 5.27142843e-02 6.40932405e-02\n",
      " 4.65369042e-02 1.28190246e-01 4.53507539e-02 3.65172368e-02\n",
      " 7.78497193e-02 5.35854961e-02 4.45038958e-02 7.29424790e-02\n",
      " 5.59701734e-02 7.46221074e-02 5.79057521e-02 6.87540622e-02\n",
      " 7.71109070e-02 4.49433808e-02 7.76136885e-02 4.34916730e-02\n",
      " 2.86585723e-02 3.78630313e-02 2.74133373e-02 6.98705861e-02\n",
      " 3.79009196e-02 3.13774410e-02 3.43233601e-02 4.91747201e-02\n",
      " 5.14611713e-02 7.89640582e-02 4.45772859e-02 4.48804818e-02\n",
      " 9.29927725e-02 6.64052319e-02 5.62844650e-02 5.23788909e-02\n",
      " 3.07050176e-02 8.24667440e-02 7.17377321e-02 8.45194841e-02\n",
      " 9.35001343e-02 4.93552404e-02 8.29416638e-02 1.32708675e-01\n",
      " 9.06657047e-02 7.48588103e-02 2.41671781e-02 3.23247420e-02\n",
      " 5.31178591e-02 1.34990099e-01 4.07181273e-02]\n"
     ]
    }
   ],
   "source": [
    "# testing normalization\n",
    "hr, step, scale_hr, scale_step = norm_data(r\"C:\\Users\\VictoriaAgain\\Downloads\\download\\80929938f623f44614a029108a740d00\\combined_heartrate.csv\",r\"C:\\Users\\VictoriaAgain\\Downloads\\download\\80929938f623f44614a029108a740d00\\combined_steps.csv\")\n",
    "print(step.flatten())\n",
    "# df_step = pd.DataFrame(step)\n",
    "# hr, step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cbda3f10-eee4-4a84-9531-2954b471950d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining heart rate and step files for each patient\n",
    "# given the day is the same -- check month and day are the same, create new 2d array with same date and corresponding heart rate + steps\n",
    "# also return patient id via substring\n",
    "\n",
    "def compile_step_hr(hr_file,step_file):\n",
    "    step_arr, step_day = timestamp_total_step(step_file)\n",
    "    hr_arr, hr_day = timestamp_avg_hr(hr_file)\n",
    "    \n",
    "    list_day = []\n",
    "    list_hr = []\n",
    "    list_step = []\n",
    "\n",
    "    # smaller functions work -- same dates -- something here is WRONG\n",
    "    for i in range(np.minimum(len(hr_day),len(step_day))):  # whichever is smaller\n",
    "        hr_date = datetime.fromtimestamp(hr_day[i]).date()\n",
    "        step_date = datetime.fromtimestamp(step_day[i]).date()\n",
    "        # hr_month = datetime.fromtimestamp(hr_day[i]).month\n",
    "        # hr_datetime_day = datetime.fromtimestamp(hr_day[i]).day\n",
    "        # step_month = datetime.fromtimestamp(step_day[i]).month\n",
    "        # step_datetime_day = datetime.fromtimestamp(step_day[i]).day\n",
    "        \n",
    "        # need double for loop in case we skip a day!\n",
    "        # print(hr_month, \",\", hr_datetime_day)\n",
    "        # print(step_month, \",\", step_datetime_day)\n",
    "        # if (hr_month == step_month and hr_datetime_day == step_datetime_day): # checking if date is the same\n",
    "        if hr_date == step_date:\n",
    "            # print(hr_arr[i], step_arr[i])\n",
    "            list_day.append(hr_day[i])\n",
    "            list_hr.append(hr_arr[i])\n",
    "            list_step.append(step_arr[i])\n",
    "        # elif (hr_datetime_day > step_datetime_day): # heartrate skips, go through rest of step days\n",
    "        elif hr_date > step_date:\n",
    "            for j in range(i,len(step_day)):\n",
    "                # if (hr_month == step_month and hr_datetime_day == datetime.fromtimestamp(step_day[j]).day):\n",
    "                if datetime.fromtimestamp(step_day[j], tz=ZoneInfo(\"America/New_York\")).date() == hr_date:\n",
    "                    list_day.append(hr_day[i])\n",
    "                    list_hr.append(hr_arr[i])\n",
    "                    list_step.append(step_arr[j])\n",
    "        elif (step_date > hr_date): # step day skips, go through rest of heart rate days\n",
    "            for k in range(i,len(hr_day)):\n",
    "                # if (hr_month == step_month and step_datetime_day == datetime.fromtimestamp(hr_day[k]).day):\n",
    "                if datetime.fromtimestamp(hr_day[k], tz=ZoneInfo(\"America/New_York\")).date() == step_date:\n",
    "                    list_day.append(hr_day[k])\n",
    "                    list_hr.append(hr_arr[k])\n",
    "                    list_step.append(step_arr[i])\n",
    "    \n",
    "    # testing\n",
    "    # list_day is correct, only shows same days in both lists\n",
    "    # for i in range(len(list_day)):\n",
    "    #     convert_day.append(datetime.fromtimestamp(list_day[i]).day)\n",
    "    # print(len(list_day),len(list_hr),len(list_step))\n",
    "    list_patient_id = [str(hr_file)[42:74]]*len(list_day)\n",
    "    # print(len(list_patient_id))\n",
    "    # print(step_arr, datetime.fromtimestamp(step_day).day, hr_arr, datetime.fromtimestamp(hr_day).day)\n",
    "    combined_arr = np.column_stack((list_patient_id,list_day,list_hr,list_step))\n",
    "    # print(combined_arr)\n",
    "    return combined_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f8434a47-2066-4ac8-9334-675eadd789fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80929938f623f44614a029108a740d00</td>\n",
       "      <td>1637412569.2489471</td>\n",
       "      <td>69.2135487315071</td>\n",
       "      <td>4106.000000000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80929938f623f44614a029108a740d00</td>\n",
       "      <td>1637470817.517382</td>\n",
       "      <td>65.08120599210537</td>\n",
       "      <td>4864.040551797268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>80929938f623f44614a029108a740d00</td>\n",
       "      <td>1637592203.2239146</td>\n",
       "      <td>81.50416158411625</td>\n",
       "      <td>7080.694108333209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80929938f623f44614a029108a740d00</td>\n",
       "      <td>1637704280.3434532</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2259.000000000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>80929938f623f44614a029108a740d00</td>\n",
       "      <td>1637758959.4615457</td>\n",
       "      <td>68.65693746122923</td>\n",
       "      <td>8495.874939185302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>80929938f623f44614a029108a740d00</td>\n",
       "      <td>1637816709.7473905</td>\n",
       "      <td>55.79595119612558</td>\n",
       "      <td>441.1142711733524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>80929938f623f44614a029108a740d00</td>\n",
       "      <td>1637942311.2620025</td>\n",
       "      <td>67.60386098514904</td>\n",
       "      <td>3820.0000000000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>80929938f623f44614a029108a740d00</td>\n",
       "      <td>1638021251.441996</td>\n",
       "      <td>66.28720432438263</td>\n",
       "      <td>1573.4198221877853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>80929938f623f44614a029108a740d00</td>\n",
       "      <td>1638075601.7114477</td>\n",
       "      <td>62.18266338031886</td>\n",
       "      <td>3163.3186441764765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>80929938f623f44614a029108a740d00</td>\n",
       "      <td>1638162003.6383348</td>\n",
       "      <td>86.04245164151678</td>\n",
       "      <td>9136.275179646467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>80929938f623f44614a029108a740d00</td>\n",
       "      <td>1638285822.3497252</td>\n",
       "      <td>75.95921241760254</td>\n",
       "      <td>4872.15902129765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>80929938f623f44614a029108a740d00</td>\n",
       "      <td>1638460143.7912552</td>\n",
       "      <td>62.46399001492799</td>\n",
       "      <td>2342.2236172496387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>80929938f623f44614a029108a740d00</td>\n",
       "      <td>1638553402.9287596</td>\n",
       "      <td>66.40421788379399</td>\n",
       "      <td>2113.9999999999995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>80929938f623f44614a029108a740d00</td>\n",
       "      <td>1638714409.6893587</td>\n",
       "      <td>64.15289858554272</td>\n",
       "      <td>664.0000000000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>80929938f623f44614a029108a740d00</td>\n",
       "      <td>1638894876.9238443</td>\n",
       "      <td>79.50205987783579</td>\n",
       "      <td>2949.629743259942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>80929938f623f44614a029108a740d00</td>\n",
       "      <td>1639068064.430778</td>\n",
       "      <td>93.08888888888889</td>\n",
       "      <td>1874.3609989468448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>80929938f623f44614a029108a740d00</td>\n",
       "      <td>1639155929.2218516</td>\n",
       "      <td>86.3323076923077</td>\n",
       "      <td>6402.2236649766355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>80929938f623f44614a029108a740d00</td>\n",
       "      <td>1639233193.9316382</td>\n",
       "      <td>76.59636599222819</td>\n",
       "      <td>5232.006582712697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>80929938f623f44614a029108a740d00</td>\n",
       "      <td>1639321418.0714412</td>\n",
       "      <td>74.99943177668808</td>\n",
       "      <td>3023.680872704431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>80929938f623f44614a029108a740d00</td>\n",
       "      <td>1639493157.0634344</td>\n",
       "      <td>81.75365752867427</td>\n",
       "      <td>6683.50935864096</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   0                   1                  2  \\\n",
       "0   80929938f623f44614a029108a740d00  1637412569.2489471   69.2135487315071   \n",
       "1   80929938f623f44614a029108a740d00   1637470817.517382  65.08120599210537   \n",
       "2   80929938f623f44614a029108a740d00  1637592203.2239146  81.50416158411625   \n",
       "3   80929938f623f44614a029108a740d00  1637704280.3434532                0.0   \n",
       "4   80929938f623f44614a029108a740d00  1637758959.4615457  68.65693746122923   \n",
       "5   80929938f623f44614a029108a740d00  1637816709.7473905  55.79595119612558   \n",
       "6   80929938f623f44614a029108a740d00  1637942311.2620025  67.60386098514904   \n",
       "7   80929938f623f44614a029108a740d00   1638021251.441996  66.28720432438263   \n",
       "8   80929938f623f44614a029108a740d00  1638075601.7114477  62.18266338031886   \n",
       "9   80929938f623f44614a029108a740d00  1638162003.6383348  86.04245164151678   \n",
       "10  80929938f623f44614a029108a740d00  1638285822.3497252  75.95921241760254   \n",
       "11  80929938f623f44614a029108a740d00  1638460143.7912552  62.46399001492799   \n",
       "12  80929938f623f44614a029108a740d00  1638553402.9287596  66.40421788379399   \n",
       "13  80929938f623f44614a029108a740d00  1638714409.6893587  64.15289858554272   \n",
       "14  80929938f623f44614a029108a740d00  1638894876.9238443  79.50205987783579   \n",
       "15  80929938f623f44614a029108a740d00   1639068064.430778  93.08888888888889   \n",
       "16  80929938f623f44614a029108a740d00  1639155929.2218516   86.3323076923077   \n",
       "17  80929938f623f44614a029108a740d00  1639233193.9316382  76.59636599222819   \n",
       "18  80929938f623f44614a029108a740d00  1639321418.0714412  74.99943177668808   \n",
       "19  80929938f623f44614a029108a740d00  1639493157.0634344  81.75365752867427   \n",
       "\n",
       "                     3  \n",
       "0    4106.000000000001  \n",
       "1    4864.040551797268  \n",
       "2    7080.694108333209  \n",
       "3    2259.000000000001  \n",
       "4    8495.874939185302  \n",
       "5    441.1142711733524  \n",
       "6   3820.0000000000014  \n",
       "7   1573.4198221877853  \n",
       "8   3163.3186441764765  \n",
       "9    9136.275179646467  \n",
       "10    4872.15902129765  \n",
       "11  2342.2236172496387  \n",
       "12  2113.9999999999995  \n",
       "13   664.0000000000001  \n",
       "14   2949.629743259942  \n",
       "15  1874.3609989468448  \n",
       "16  6402.2236649766355  \n",
       "17   5232.006582712697  \n",
       "18   3023.680872704431  \n",
       "19    6683.50935864096  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing\n",
    "\n",
    "# taking array and turning into csv file\n",
    "arr = compile_step_hr(r\"C:\\Users\\VictoriaAgain\\Downloads\\download\\80929938f623f44614a029108a740d00\\combined_heartrate.csv\",r\"C:\\Users\\VictoriaAgain\\Downloads\\download\\80929938f623f44614a029108a740d00\\combined_steps.csv\")\n",
    "# arr = compile_step_hr(r\"C:\\Users\\VictoriaAgain\\Downloads\\download\\90b8c2e2c843ffd77f8621c7d6ed044d\\combined_heartrate.csv\",r\"C:\\Users\\VictoriaAgain\\Downloads\\download\\90b8c2e2c843ffd77f8621c7d6ed044d\\combined_steps.csv\")\n",
    "\n",
    "df = pd.DataFrame(arr)\n",
    "df.head(20)\n",
    "# patient_id time hr step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "e6203f1b-d6a3-414a-876c-ac44ce3ac2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# given a folder go through each of the folders and create an array based on the combined heartrate and steps\n",
    "\n",
    "p = Path(\"C:/Users/VictoriaAgain/Downloads/download\")\n",
    "raw_files = list(p.rglob('*.csv*'))\n",
    "files = []\n",
    "all_files = []\n",
    "\n",
    "for i in range(len(raw_files)):\n",
    "    files.append(str(raw_files[i]).replace('\\\\','/'))\n",
    "for j in range(len(files)-1):\n",
    "    all_files.append(compile_step_hr(files[j],files[j+1]))\n",
    "\n",
    "final_df = pd.DataFrame(np.vstack(all_files),columns=['patient_id','timestamp','average_hr','steps'])\n",
    "final_df.to_csv('combined_files_avg_hr.csv',index=False,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d74efe50-36d0-48ff-873c-87e0583ec11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at different classification models!!\n",
    "# sk learn package -- regression tracking, classification -- try and use classifier!\n",
    "\n",
    "# new function -- go through all of the folders and json files, create a csv file with all of the daily PROMIS responses, days, and patient_id\n",
    "# if json file has daily faigue 1 item, put patient_id, promis score, and date in big csv file\n",
    "# go through both hr_step and promis_file, combined based on dates and patient_id\n",
    "\n",
    "def compile_fatigue(folder_path):\n",
    "    p = Path(folder_path)\n",
    "    raw_promis_files = list(p.rglob('*.json*')) # all json files\n",
    "    daily_promis_files = []\n",
    "    \n",
    "    for i in range(len(raw_promis_files)):\n",
    "        readable_promis_file = ((str(raw_promis_files[i])).replace('\\\\','/')) # converts all survey files into inputtable format\n",
    "        df = pd.read_json(readable_promis_file)\n",
    "        temp_daily_arr = []\n",
    "        if 'DailyFatigue_1Item' in df['answers'] and 'key' in df.columns:\n",
    "            temp_daily_arr.append(str(readable_promis_file)[72:104])\n",
    "            temp_daily_arr.append(int(str(df['key'])[27:29])) # month\n",
    "            temp_daily_arr.append(int(str(df['key'])[30:32])) # day\n",
    "            temp_daily_arr.append(df['answers']['DailyFatigue_1Item'])\n",
    "            daily_promis_files.append(temp_daily_arr)\n",
    "            temp_daily_arr = []\n",
    "    return daily_promis_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d3043818-32dc-44e4-a775-69a80a6aaf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing\n",
    "\n",
    "df = pd.DataFrame(np.vstack(compile_fatigue(r\"C:\\Users\\VictoriaAgain\\Downloads\\surveys-20250613T020413Z-1-001\\surveys\")),columns=['patient_id','month','day','promis_score'])\n",
    "df.to_csv('combined_promis_scores.csv',index=False,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "261310a3-a7be-463b-96f3-1a940a75f200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparing both average heartrate and promis score files\n",
    "# given both files, find where dates (unix time to month + date) match up and patient_id matches\n",
    "# add all information to new combined csv file\n",
    "\n",
    "df_hr = pd.read_csv('combined_files_avg_hr.csv')\n",
    "df_promis = pd.read_csv('combined_promis_scores.csv')\n",
    "\n",
    "# convert timestamp to datetime and extract month + day\n",
    "df_hr['datetime'] = pd.to_datetime(df_hr['timestamp'], unit='s')\n",
    "df_hr['month'] = df_hr['datetime'].dt.month\n",
    "df_hr['day'] = df_hr['datetime'].dt.day\n",
    "\n",
    "# filter cols\n",
    "df_hr_filtered = df_hr[['patient_id', 'month', 'day', 'average_hr', 'steps']]\n",
    "\n",
    "# merge dfs on patient_id, month, and day\n",
    "df_merged = pd.merge(df_promis, df_hr_filtered,\n",
    "                     on = ['patient_id', 'month', 'day'],\n",
    "                     how = 'inner')\n",
    "\n",
    "df_final = df_merged[['patient_id', 'month', 'day', 'average_hr', 'steps', 'promis_score']]\n",
    "df_final.columns = ['patient id', 'month', 'day', 'heartrate', 'steps', 'promis score']\n",
    "\n",
    "df_final.to_csv('final_avg_hr_data_updated.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f817a1e-2d06-4cb2-9249-317e65bca411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting promis scores to numerical values\n",
    "\n",
    "def compile_fatigue_numbers(folder_path):\n",
    "    p = Path(folder_path)\n",
    "    raw_promis_files = list(p.rglob('*.json*')) # all json files\n",
    "    daily_promis_numbers = []\n",
    "    \n",
    "    for i in range(len(raw_promis_files)):\n",
    "        readable_promis_file = ((str(raw_promis_files[i])).replace('\\\\','/')) # converts all survey files into inputtable format\n",
    "        df = pd.read_json(readable_promis_file)\n",
    "        temp_daily_arr = []\n",
    "        if 'DailyFatigue_1Item' in df['answers'] and 'key' in df.columns:\n",
    "            temp_daily_arr.append(str(readable_promis_file)[72:104])\n",
    "            temp_daily_arr.append(int(str(df['key'])[27:29])) # month\n",
    "            temp_daily_arr.append(int(str(df['key'])[30:32])) # day\n",
    "            promis_score = df['answers']['DailyFatigue_1Item']\n",
    "            if promis_score == 'Not fatigued at all':\n",
    "                temp_daily_arr.append(0)\n",
    "            elif promis_score == 'A little bit fatigued':\n",
    "                temp_daily_arr.append(1)\n",
    "            elif promis_score == 'Somewhat fatigued':\n",
    "                temp_daily_arr.append(2)\n",
    "            elif promis_score == 'Very fatigued':\n",
    "                temp_daily_arr.append(3)\n",
    "            daily_promis_numbers.append(temp_daily_arr)\n",
    "            temp_daily_arr = []\n",
    "    return daily_promis_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a40da94-c6f5-4137-a4bf-49be9cf35805",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.vstack(compile_fatigue_numbers(r\"C:\\Users\\VictoriaAgain\\Downloads\\surveys-20250613T020413Z-1-001\\surveys\")),columns=['patient_id','month','day','promis_score'])\n",
    "df.to_csv('combined_promis_nums.csv',index=False,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "855cad90-d27c-4f8f-86cd-14c5967ab0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hr = pd.read_csv('combined_files_avg_hr.csv')\n",
    "df_promis = pd.read_csv('combined_promis_nums.csv')\n",
    "\n",
    "# convert timestamp to datetime and extract month + day\n",
    "df_hr['datetime'] = pd.to_datetime(df_hr['timestamp'], unit='s')\n",
    "df_hr['month'] = df_hr['datetime'].dt.month\n",
    "df_hr['day'] = df_hr['datetime'].dt.day\n",
    "\n",
    "# filter cols\n",
    "df_hr_filtered = df_hr[['patient_id', 'month', 'day', 'average_hr', 'steps']]\n",
    "\n",
    "# merge dfs on patient_id, month, and day\n",
    "df_merged = pd.merge(df_promis, df_hr_filtered,\n",
    "                     on = ['patient_id', 'month', 'day'],\n",
    "                     how = 'inner')\n",
    "\n",
    "df_final = df_merged[['patient_id', 'month', 'day', 'average_hr', 'steps', 'promis_score']]\n",
    "df_final.columns = ['patient id', 'month', 'day', 'heartrate', 'steps', 'promis score']\n",
    "\n",
    "df_final.to_csv('final_avg_hr_nums_updated.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8663f7-3e19-4794-93df-c10a2b8759af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
